{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Development prerequisites\n",
    "\n",
    "- Run `source ./setup_aws_glue_scripts/setup_aws_glue.sh` in GitBash\n",
    "\n",
    "AWS Glue Local Debugging:\n",
    "> Run `./glue_local_debug.sh` or follow the following steps.\n",
    "\n",
    "- From the Command Palette (`Ctrl+Shift+P`), select `Tasks: Run Task command`, then select `Convert Notebook to Script`\n",
    "- Run `pipenv shell` in terminal\n",
    "- Run `jupyter notebook --no-browser` in terminal\n",
    "- Copy Jupyter Server url from terminal\n",
    "- From the Command Palette (`Ctrl+Shift+P`), select `Notebook: Select Notebook Kernel`, then select `Select Another Kernel...`, then select `Existing Jupyter Server...`, then paste Jupyter Server url, then enter, then enter again.\n",
    "\n",
    "AWS Glue Interactive Session Debugging:\n",
    "- From the Command Palette (`Ctrl+Shift+P`), select `Tasks: Run Task command`, then select `Convert Notebook to Script`\n",
    "- Run `pipenv shell` in terminal\n",
    "- Run `jupyter notebook --no-browser` in terminal\n",
    "- Copy Jupyter Server url from terminal\n",
    "- From the Command Palette (`Ctrl+Shift+P`), select `Notebook: Select Notebook Kernel`, then select `Select Another Kernel...`, then select `Existing Jupyter Server...`, then paste Jupyter Server url, then enter, then enter again.\n",
    "- Uncomment the following cell, and run it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To configure AWS Glue Interactive Session, uncomment the following cell\n",
    "\n",
    "Change configuration in terms of your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %profile [your-profile-name]\n",
    "# %region eu-west-1\n",
    "# %iam_role [your-iam-role]\n",
    "# %worker_type G.1X\n",
    "# %number_of_workers 2\n",
    "# %additional_python_modules watchtower\n",
    "# %extra_py_files s3://artifacts-dev/33333/Layers/pip_common_packages_layer_glue.zip,s3://artifacts-dev/33333/Layers/combined_lambda_layer_glue.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To pass system arguments, uncomment the following cell\n",
    "\n",
    "Change arguments in terms of your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "stage = \"dev\"\n",
    "current_time = datetime.now()\n",
    "\n",
    "sys.argv = [\n",
    "    \"convert_csv_to_parque_glue_job.py\",  # sys.argv[0], script name\n",
    "    \"true\",\n",
    "    \"--is_local\",\n",
    "    \"true\",\n",
    "    \"--job-bookmark-option\",\n",
    "    \"job-bookmark-disable\",\n",
    "    \"--JOB_ID\",\n",
    "    \"j_a197e5a4ae431ff7631a35bdcddbb8b6bebf747667c548020bfbd40447569b25\",\n",
    "    \"true\",\n",
    "    \"--stage\",\n",
    "    \"dev\",\n",
    "    \"--JOB_RUN_ID\",\n",
    "    \"jr_6a23882f8589db824567693a787ec1014a66dcc868186c2cb8ae26a502f47040\",\n",
    "    \"--JOB_NAME\",\n",
    "    \"TEST_JOB\",\n",
    "    \"--execution_arn\",\n",
    "    f\"arn:aws:states:eu-west-1:625904187796:execution:TEST_JOB:try-{current_time.strftime('%Y%m%d%H%M%S%f')}\",\n",
    "    \"--debugging\",\n",
    "    \"True\",\n",
    "    \"--stage\",\n",
    "    stage,\n",
    "    \"--log_group_name\",\n",
    "    f\"/aws-glue/jobs/convert-csv-to-parque-glue-job-{stage}\",\n",
    "    \"--total_records\",\n",
    "    \"1000\",\n",
    "    \"--s3_file_path\",\n",
    "    \"test\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize AWS Glue Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "from glue_utils import argv_to_dict\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.utils import getResolvedOptions\n",
    "\n",
    "\n",
    "# Get parameters passed to the script\n",
    "args = getResolvedOptions(\n",
    "    sys.argv,\n",
    "    [\n",
    "        \"JOB_NAME\",\n",
    "        \"execution_arn\",\n",
    "        \"debugging\",\n",
    "        \"log_group_name\",\n",
    "        \"total_records\",\n",
    "        \"stage\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Initialize Glue context\n",
    "sparkContext = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sparkContext=sparkContext)\n",
    "spark = glueContext.spark_session\n",
    "logger = glueContext.get_logger()\n",
    "job = Job(glueContext)\n",
    "job.init(args[\"JOB_NAME\"], args)\n",
    "\n",
    "print(\"sys.argv to dictionary\")\n",
    "print(\"**********************\")\n",
    "print(json.dumps(obj=sys.argv, indent=4))\n",
    "\n",
    "args = argv_to_dict(argv=sys.argv)\n",
    "\n",
    "args_json = json.dumps(args, indent=4)\n",
    "\n",
    "print(\"args to dictionary\")\n",
    "print(\"**********************\")\n",
    "print(args_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To configure AWS Cloudwatch Logging(Mandatory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_cloudwatch_logging import setup_cloudwatch_logging\n",
    "\n",
    "\n",
    "setup_cloudwatch_logging(\n",
    "    log_group_name=args[\"log_group_name\"],\n",
    "    log_stream_name=args[\"JOB_RUN_ID\"],\n",
    "    job_name=args[\"job\"],\n",
    "    execution_arn=args[\"execution_arn\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    logger.info(f\"Beginning the job...\")\n",
    "\n",
    "    data = [(\"John\", 28), (\"Anna\", 23), (\"Mike\", 35), (\"Sara\", 29)]\n",
    "\n",
    "    # Create DataFrame from data\n",
    "    columns = [\"Name\", \"Age\"]\n",
    "    \n",
    "    df = spark.createDataFrame(data, columns)\n",
    "\n",
    "    # Show DataFrame\n",
    "    df.show()\n",
    "\n",
    "    # Select specific columns\n",
    "    df.select(\"Name\").show()\n",
    "\n",
    "    # Filter rows based on conditions\n",
    "    df.filter(df[\"Age\"] > 25).show()\n",
    "\n",
    "    # Group by a column and aggregate data\n",
    "    df.groupBy(\"Age\").count().show()\n",
    "\n",
    "    logger.info(\"Ending the job...\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error encountered during the job: {str(e)}\", exc_info=True)\n",
    "finally:\n",
    "    job.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AWS Glue Jupyter Local",
   "language": "python",
   "name": "aws_glue_jupyter_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
